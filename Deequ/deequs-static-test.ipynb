{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4984fe1-fe2d-4531-86a9-cb55796f1042",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Static Data Quality Analysis using AWS Deequ\n",
    "\n",
    "This notebook demonstrates how to perform data quality analysis using AWS Deequ on a static dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93b07e19-367a-4694-9fb9-cfd98dee834d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Setup and Data Preparation\n",
    "\n",
    "First, import necessary libraries and setup the environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef09df6d-f854-4aba-b107-e0c7b4e44e74",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">import spark.implicits._\n",
       "import org.apache.spark.sql._\n",
       "import org.apache.spark.sql.functions._\n",
       "import com.amazon.deequ.{VerificationSuite, VerificationResult}\n",
       "import com.amazon.deequ.VerificationResult.checkResultsAsDataFrame\n",
       "import com.amazon.deequ.checks.{Check, CheckLevel, CheckStatus}\n",
       "import com.amazon.deequ.suggestions.{ConstraintSuggestionRunner, Rules}\n",
       "import com.amazon.deequ.analyzers._\n",
       "import com.amazon.deequ.analyzers.runners.AnalysisRunner\n",
       "import com.amazon.deequ.analyzers.runners.AnalyzerContext.successMetricsAsDataFrame\n",
       "import com.amazon.deequ.analyzers.{Analysis, ApproxCountDistinct, Completeness, Compliance, Distinctness}\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">import spark.implicits._\nimport org.apache.spark.sql._\nimport org.apache.spark.sql.functions._\nimport com.amazon.deequ.{VerificationSuite, VerificationResult}\nimport com.amazon.deequ.VerificationResult.checkResultsAsDataFrame\nimport com.amazon.deequ.checks.{Check, CheckLevel, CheckStatus}\nimport com.amazon.deequ.suggestions.{ConstraintSuggestionRunner, Rules}\nimport com.amazon.deequ.analyzers._\nimport com.amazon.deequ.analyzers.runners.AnalysisRunner\nimport com.amazon.deequ.analyzers.runners.AnalyzerContext.successMetricsAsDataFrame\nimport com.amazon.deequ.analyzers.{Analysis, ApproxCountDistinct, Completeness, Compliance, Distinctness}\n</div>",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%scala\n",
    "import spark.implicits._\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "import com.amazon.deequ.{VerificationSuite, VerificationResult}\n",
    "import com.amazon.deequ.VerificationResult.checkResultsAsDataFrame\n",
    "import com.amazon.deequ.checks.{Check, CheckLevel, CheckStatus}\n",
    "import com.amazon.deequ.suggestions.{ConstraintSuggestionRunner, Rules}\n",
    "import com.amazon.deequ.analyzers._\n",
    "import com.amazon.deequ.analyzers.runners.AnalysisRunner\n",
    "import com.amazon.deequ.analyzers.runners.AnalyzerContext.successMetricsAsDataFrame\n",
    "import com.amazon.deequ.analyzers.{Analysis, ApproxCountDistinct, Completeness, Compliance, Distinctness}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5327e63c-97be-45cf-a2ca-43893eb89777",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">data_path: String = /FileStore/tables/stockTicks.json\n",
       "base_df: org.apache.spark.sql.DataFrame = [buysell: string, date: string ... 6 more fields]\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">data_path: String = /FileStore/tables/stockTicks.json\nbase_df: org.apache.spark.sql.DataFrame = [buysell: string, date: string ... 6 more fields]\n</div>",
       "datasetInfos": [
        {
         "name": "base_df",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "buysell",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "date",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ipaddr",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ordertype",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "price",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "quantity",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "symbol",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "time",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "org.apache.spark.sql.DataFrame"
        }
       ],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%scala\n",
    "\n",
    "\n",
    "// Load the static dataset\n",
    "val data_path = \"/FileStore/tables/stockTicks.json\"\n",
    "val base_df = spark.read.json(data_path)\n",
    "\n",
    "base_df.createOrReplaceTempView(\"static_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ee03970-a2d9-4324-ad5c-243307d5b3fc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Analyze Data Quality with AWS Deequ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe8af334-6783-494b-a591-97318eee2154",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%scala\n",
    "// Suggest constraints based on the static dataset\n",
    "val suggestionResult = ConstraintSuggestionRunner()\n",
    "  .onData(spark.sql(\"SELECT * FROM static_data\"))\n",
    "  .addConstraintRules(Rules.DEFAULT)\n",
    "  .run()\n",
    "\n",
    "suggestionResult.constraintSuggestions.foreach { case (column, suggestions) =>\n",
    "  suggestions.foreach { suggestion =>\n",
    "    println(s\"Constraint suggestion for '$column':\\t${suggestion.description}\\n\" +\n",
    "    s\"The corresponding scala code is: ${suggestion.codeForConstraint}\\n\")\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "// # %scala\n",
    "// # // Suggest constraints based on the static dataset\n",
    "// # val suggestionResult = ConstraintSuggestionRunner()\n",
    "// #   .onData(spark.sql(\"SELECT * FROM static_data\"))\n",
    "// #   .addConstraintRules(Rules.DEFAULT)\n",
    "// #   .run()\n",
    "\n",
    "// # suggestionResult.constraintSuggestions.foreach { case (column, suggestions) =>\n",
    "// #   suggestions.foreach { suggestion =>\n",
    "// #     println(s\"Constraint suggestion for '$column':\\t${suggestion.description}\\n\" +\n",
    "// #     s\"The corresponding scala code is: ${suggestion.codeForConstraint}\\n\")\n",
    "// #   }\n",
    "// # }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a01c0e09-d161-421d-8c7a-64742ba14c60",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Perform Data Quality Checks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77eeaf11-1ef8-4c61-a5a6-d29a827b8aac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>entity</th><th>instance</th><th>name</th><th>value</th></tr></thead><tbody><tr><td>Column</td><td>quantity</td><td>Uniqueness</td><td>0.9528301886792453</td></tr><tr><td>Column</td><td>buysell</td><td>Uniqueness</td><td>0.0</td></tr><tr><td>Column</td><td>ipaddr</td><td>Uniqueness</td><td>1.0</td></tr><tr><td>Column</td><td>date</td><td>Uniqueness</td><td>0.0</td></tr><tr><td>Column</td><td>symbol</td><td>Uniqueness</td><td>0.864</td></tr><tr><td>Column</td><td>ordertype</td><td>Uniqueness</td><td>0.0</td></tr><tr><td>Column</td><td>time</td><td>Uniqueness</td><td>0.992</td></tr><tr><td>Column</td><td>price</td><td>Uniqueness</td><td>0.9837067209775967</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Column",
         "quantity",
         "Uniqueness",
         0.9528301886792453
        ],
        [
         "Column",
         "buysell",
         "Uniqueness",
         0.0
        ],
        [
         "Column",
         "ipaddr",
         "Uniqueness",
         1.0
        ],
        [
         "Column",
         "date",
         "Uniqueness",
         0.0
        ],
        [
         "Column",
         "symbol",
         "Uniqueness",
         0.864
        ],
        [
         "Column",
         "ordertype",
         "Uniqueness",
         0.0
        ],
        [
         "Column",
         "time",
         "Uniqueness",
         0.992
        ],
        [
         "Column",
         "price",
         "Uniqueness",
         0.9837067209775967
        ]
       ],
       "datasetInfos": [
        {
         "name": "metricsDataFrame",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "entity",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "instance",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "value",
            "nullable": false,
            "type": "double"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "org.apache.spark.sql.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "entity",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "instance",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "value",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%scala\n",
    "\n",
    "// Deequ执行前的时间戳\n",
    "val startTimeDeequ = System.nanoTime()\n",
    "\n",
    "val analysis = Analysis()\n",
    "  .addAnalyzer(Size())\n",
    "  .addAnalyzer(ApproxCountDistinct(\"symbol\"))\n",
    "  .addAnalyzer(Uniqueness(\"buysell\"))\n",
    "  .addAnalyzer(Uniqueness(\"date\"))\n",
    "  .addAnalyzer(Uniqueness(\"ipaddr\"))\n",
    "  .addAnalyzer(Uniqueness(\"ordertype\"))\n",
    "  .addAnalyzer(Uniqueness(\"price\"))\n",
    "  .addAnalyzer(Uniqueness(\"quantity\"))\n",
    "  .addAnalyzer(Uniqueness(\"symbol\"))\n",
    "  .addAnalyzer(Uniqueness(\"time\"))\n",
    "  .addAnalyzer(Completeness(\"ipaddr\"))\n",
    "  .addAnalyzer(Completeness(\"symbol\"))\n",
    "  .addAnalyzer(Completeness(\"quantity\"))\n",
    "  .addAnalyzer(Completeness(\"price\"))\n",
    "  .addAnalyzer(Compliance(\"positive quantity\", \"quantity >= 0\"))\n",
    "\n",
    "val analysisResult = AnalysisRunner\n",
    "  .onData(base_df)\n",
    "  .addAnalyzers(analysis.analyzers)\n",
    "  .run()\n",
    "\n",
    "// // Deequ执行后的时间戳\n",
    "// val endTimeDeequ = System.nanoTime()\n",
    "\n",
    "// // 计算运行时间（转换为毫秒）\n",
    "// val durationDeequ = (endTimeDeequ - startTimeDeequ) / 1e6d\n",
    "// println(s\"Deequ test runtime: $durationDeequ milliseconds\")\n",
    "\n",
    "// Convert analysis results to DataFrame for visualization\n",
    "val metricsDataFrame = successMetricsAsDataFrame(spark, analysisResult)\n",
    "display(metricsDataFrame)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "// # val analysis = Analysis()\n",
    "// #   .addAnalyzer(Size())\n",
    "// #   .addAnalyzer(ApproxCountDistinct(\"title\"))\n",
    "// #   .addAnalyzer(Distinctness(\"title\"))\n",
    "// #   .addAnalyzer(Completeness(\"title\"))\n",
    "// #   .addAnalyzer(Completeness(\"release_date\"))\n",
    "// #   .addAnalyzer(Completeness(\"rating\"))\n",
    "// #   .addAnalyzer(Completeness(\"description\"))\n",
    "// #   .addAnalyzer(Compliance(\"rating\", \"rating >= 0\"))\n",
    "\n",
    "\n",
    "// # val analysisResult = AnalysisRunner\n",
    "// #   .onData(base_df)\n",
    "// #   .addAnalyzers(analysis.analyzers)\n",
    "// #   .run()\n",
    "\n",
    "// # // Convert analysis results to DataFrame for visualization\n",
    "// # val metricsDataFrame = successMetricsAsDataFrame(spark, analysisResult)\n",
    "// # display(metricsDataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "819699c7-2064-43cc-a1d7-03e268c20dc7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Verification of Data Quality Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd33d37e-7e6b-4f52-94a7-32396cdd986b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>check</th><th>check_level</th><th>check_status</th><th>constraint</th><th>constraint_status</th><th>constraint_message</th></tr></thead><tbody><tr><td>Data Quality Verification</td><td>Error</td><td>Error</td><td>UniquenessConstraint(Uniqueness(List(buysell),None))</td><td>Failure</td><td>Value: 0.0 does not meet the constraint requirement!</td></tr><tr><td>Data Quality Verification</td><td>Error</td><td>Error</td><td>UniquenessConstraint(Uniqueness(List(date),None))</td><td>Failure</td><td>Value: 0.0 does not meet the constraint requirement!</td></tr><tr><td>Data Quality Verification</td><td>Error</td><td>Error</td><td>UniquenessConstraint(Uniqueness(List(ipaddr),None))</td><td>Success</td><td></td></tr><tr><td>Data Quality Verification</td><td>Error</td><td>Error</td><td>UniquenessConstraint(Uniqueness(List(ordertype),None))</td><td>Failure</td><td>Value: 0.0 does not meet the constraint requirement!</td></tr><tr><td>Data Quality Verification</td><td>Error</td><td>Error</td><td>UniquenessConstraint(Uniqueness(List(price),None))</td><td>Failure</td><td>Value: 0.9837067209775967 does not meet the constraint requirement!</td></tr><tr><td>Data Quality Verification</td><td>Error</td><td>Error</td><td>UniquenessConstraint(Uniqueness(List(quantity),None))</td><td>Failure</td><td>Value: 0.9528301886792453 does not meet the constraint requirement!</td></tr><tr><td>Data Quality Verification</td><td>Error</td><td>Error</td><td>UniquenessConstraint(Uniqueness(List(symbol),None))</td><td>Failure</td><td>Value: 0.864 does not meet the constraint requirement!</td></tr><tr><td>Data Quality Verification</td><td>Error</td><td>Error</td><td>UniquenessConstraint(Uniqueness(List(time),None))</td><td>Failure</td><td>Value: 0.992 does not meet the constraint requirement!</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Data Quality Verification",
         "Error",
         "Error",
         "UniquenessConstraint(Uniqueness(List(buysell),None))",
         "Failure",
         "Value: 0.0 does not meet the constraint requirement!"
        ],
        [
         "Data Quality Verification",
         "Error",
         "Error",
         "UniquenessConstraint(Uniqueness(List(date),None))",
         "Failure",
         "Value: 0.0 does not meet the constraint requirement!"
        ],
        [
         "Data Quality Verification",
         "Error",
         "Error",
         "UniquenessConstraint(Uniqueness(List(ipaddr),None))",
         "Success",
         ""
        ],
        [
         "Data Quality Verification",
         "Error",
         "Error",
         "UniquenessConstraint(Uniqueness(List(ordertype),None))",
         "Failure",
         "Value: 0.0 does not meet the constraint requirement!"
        ],
        [
         "Data Quality Verification",
         "Error",
         "Error",
         "UniquenessConstraint(Uniqueness(List(price),None))",
         "Failure",
         "Value: 0.9837067209775967 does not meet the constraint requirement!"
        ],
        [
         "Data Quality Verification",
         "Error",
         "Error",
         "UniquenessConstraint(Uniqueness(List(quantity),None))",
         "Failure",
         "Value: 0.9528301886792453 does not meet the constraint requirement!"
        ],
        [
         "Data Quality Verification",
         "Error",
         "Error",
         "UniquenessConstraint(Uniqueness(List(symbol),None))",
         "Failure",
         "Value: 0.864 does not meet the constraint requirement!"
        ],
        [
         "Data Quality Verification",
         "Error",
         "Error",
         "UniquenessConstraint(Uniqueness(List(time),None))",
         "Failure",
         "Value: 0.992 does not meet the constraint requirement!"
        ]
       ],
       "datasetInfos": [
        {
         "name": "resultDataFrame",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "check",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "check_level",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "check_status",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "constraint",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "constraint_status",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "constraint_message",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "org.apache.spark.sql.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "check",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "check_level",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "check_status",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "constraint",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "constraint_status",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "constraint_message",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%scala\n",
    "val verificationResult: VerificationResult = VerificationSuite()\n",
    "  .onData(base_df)\n",
    "  .addCheck(\n",
    "    Check(CheckLevel.Error, \"Data Quality Verification\")\n",
    "    .hasSize(_ == 1000)\n",
    "    .isComplete(\"buysell\") \n",
    "    .isComplete(\"date\") \n",
    "    .isComplete(\"ipaddr\") \n",
    "    .isComplete(\"ordertype\") \n",
    "    .isComplete(\"price\") \n",
    "    .isComplete(\"quantity\") \n",
    "    .isComplete(\"symbol\") \n",
    "    .isComplete(\"time\") \n",
    "    .isUnique(\"buysell\") \n",
    "    .isUnique(\"date\") \n",
    "    .isUnique(\"ipaddr\") \n",
    "    .isUnique(\"ordertype\") \n",
    "    .isUnique(\"price\") \n",
    "    .isUnique(\"quantity\") \n",
    "    .isUnique(\"symbol\") \n",
    "    .isUnique(\"time\") \n",
    "    .hasDistinctness(Seq(\"buysell\"), _ >= 0.1) \n",
    "    .hasDistinctness(Seq(\"date\"), _ >= 0.1) \n",
    "    .hasDistinctness(Seq(\"ipaddr\"), _ >= 0.1) \n",
    "    .hasDistinctness(Seq(\"ordertype\"), _ >= 0.1) \n",
    "    .hasDistinctness(Seq(\"price\"), _ >= 0.1) \n",
    "    .hasDistinctness(Seq(\"quantity\"), _ >= 0.1) \n",
    "    .hasDistinctness(Seq(\"symbol\"), _ >= 0.1) \n",
    "    .hasDistinctness(Seq(\"time\"), _ >= 0.1) \n",
    "    .hasApproxQuantile(\"price\", 0.5, _ <= 40)\n",
    "    .hasApproxQuantile(\"quantity\", 0.5, _ <= 2000)\n",
    "    .isNonNegative(\"price\")\n",
    "    .isNonNegative(\"quantity\")\n",
    "  )\n",
    "  .run()\n",
    "\n",
    "  val resultDataFrame = checkResultsAsDataFrame(spark, verificationResult)\n",
    "  display(resultDataFrame)\n",
    "\n",
    "\n",
    "    // .hasDistinctness(\"date\", _ >= 0.1) \n",
    "    // .hasDistinctness(\"ipaddr\", _ >= 0.1) \n",
    "    // .hasDistinctness(\"ordertype\", _ >= 0.1) \n",
    "    // .hasDistinctness(\"price\", _ >= 0.1) \n",
    "    // .hasDistinctness(\"quantity\", _ >= 0.1) \n",
    "    // .hasDistinctness(\"symbol\", _ >= 0.1) \n",
    "    // .hasDistinctness(\"time\", _ >= 0.1) \n",
    "    // .isNonNegative(\"quantity\", _ >= 0.1)\n",
    "    // .hasDistinctness()\n",
    "    // .hasCompleteness(\"title\", _ >= 0.95)\n",
    "    // .isUnique(\"title\")\n",
    "    // .hasCompleteness(\"ipaddr\", _ >= 0.95)\n",
    "    // // .isContainedIn(\"buysell\", Array(\"buy\", \"sell\"))\n",
    "    // .isNonNegative(\"quantity\")\n",
    "  \n",
    "\n",
    "\n",
    "// val verificationResult = VerificationSuite()\n",
    "//   .onData(data)\n",
    "//   .addCheck(\n",
    "//     Check(CheckLevel.Error, \"unit testing my data\")\n",
    "//       .hasSize(_ == 5) // we expect 5 rows\n",
    "//       .isComplete(\"id\") // should never be NULL\n",
    "//       .isUnique(\"id\") // should not contain duplicates\n",
    "//       .isComplete(\"productName\") // should never be NULL\n",
    "//       // should only contain the values \"high\" and \"low\"\n",
    "//       .isContainedIn(\"priority\", Array(\"high\", \"low\"))\n",
    "//       .isNonNegative(\"numViews\") // should not contain negative values\n",
    "//       // at least half of the descriptions should contain a url\n",
    "//       .containsURL(\"description\", _ >= 0.5)\n",
    "//       // half of the items should have less than 10 views\n",
    "//       .hasApproxQuantile(\"numViews\", 0.5, _ <= 10))\n",
    "//     .run()\n",
    "\n",
    "  // .addAnalyzer(ApproxCountDistinct(\"title\"))\n",
    "  // .addAnalyzer(Distinctness(\"title\"))\n",
    "  // .addAnalyzer(Completeness(\"release_date\"))\n",
    "  // .addAnalyzer(Completeness(\"rating\"))\n",
    "  // .addAnalyzer(Completeness(\"description\"))\n",
    "  // .addAnalyzer(Compliance(\"rating\", \"rating >= 0\"))\n",
    "\n",
    "\n",
    "  // Convert check results to a Spark data frame for visualization\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [
    {
     "elements": [],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": false
     },
     "nuid": "35e1da5c-fcb4-4e08-b146-82bb44291fb6",
     "origId": 1001574583549912,
     "title": "DQ Status Dashboard",
     "version": "DashboardViewV1",
     "width": 1440
    },
    {
     "elements": [],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "ee73f20b-cacf-4fc3-ae86-e1ce84a30a04",
     "origId": 1001574583549913,
     "title": "Untitled",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2997421437127377,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Deequ Static Test",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
